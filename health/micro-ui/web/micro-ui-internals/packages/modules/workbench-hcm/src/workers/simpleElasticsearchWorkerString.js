

// Simple Elasticsearch Worker String Export - for build compatibility
export const simpleElasticsearchWorkerString = `
// Simple Elasticsearch Worker - User Configurable
// Handles count query, batching, and parallel fetching automatically
// Now includes Scroll API support for large datasets (>10k records)

// Global state for request management
const activeRequests = new Map();
let currentRequestId = null;
let isCancelled = false;

// Global authentication state
let isAuthenticated = false;
let authenticationInProgress = false;
let authenticationPromise = null;
let lastAuthConfig = null;
const AUTH_SESSION_TIMEOUT = 30 * 60 * 1000; // 30 minutes
let authSessionExpiry = null;
let authRetryCount = 0;
const MAX_AUTH_RETRIES = 3;

// Worker message handler
self.onmessage = async function(e) {
  const { type, payload } = e.data;

  try {
    switch (type) {
      case 'AUTHENTICATE_KIBANA':
        await authenticateKibana(payload);
        break;
      case 'FETCH_DATA':
        await fetchElasticsearchData(payload);
        break;
      case 'CANCEL_REQUEST':
        if (payload.requestId) {
          if (activeRequests.has(payload.requestId)) {
            activeRequests.delete(payload.requestId);
            console.log(\`üö´ Cancelled request: \${payload.requestId}\`);
          }
          
          if (currentRequestId === payload.requestId) {
            isCancelled = true;
          }
          
          postMessage({
            type: 'FETCH_CANCELLED',
            payload: { requestId: payload.requestId }
          });
        }
        break;
      default:
        postMessage({
          type: 'ERROR',
          error: 'Unknown message type: ' + type
        });
    }
  } catch (error) {
    postMessage({
      type: 'ERROR',
      error: error.message,
      stack: error.stack
    });
  }
};

// Check if authentication is still valid
function isAuthenticationValid(authConfig) {
  if (!isAuthenticated || !authSessionExpiry || !lastAuthConfig) {
    return false;
  }
  
  // Check if session expired
  if (Date.now() > authSessionExpiry) {
    console.log('üîê Authentication session expired');
    isAuthenticated = false;
    authSessionExpiry = null;
    lastAuthConfig = null;
    return false;
  }
  
  // Check if auth config changed
  const currentConfig = \`\${authConfig.origin}|\${authConfig.kibanaPath}|\${authConfig.username}|\${authConfig.password}\`;
  if (lastAuthConfig !== currentConfig) {
    console.log('üîê Authentication config changed, re-authentication required');
    isAuthenticated = false;
    authSessionExpiry = null;
    lastAuthConfig = null;
    return false;
  }
  
  return true;
}

// Authenticate with Kibana (with concurrent request handling)
async function authenticateKibana(authConfig) {
  const { origin, kibanaPath, username, password, requestId } = authConfig;
  
  try {
    // Check if already authenticated and session is valid
    if (isAuthenticationValid(authConfig)) {
      console.log('‚úÖ Using existing authentication session');
      authRetryCount = 0; // Reset retry count on successful validation
      return;
    }
    
    // Check if we've exceeded max retries
    if (authRetryCount >= MAX_AUTH_RETRIES) {
      console.error(\`‚ùå Authentication failed after \${MAX_AUTH_RETRIES} attempts\`);
      authRetryCount = 0; // Reset for future attempts
      throw new Error(\`Authentication failed after \${MAX_AUTH_RETRIES} attempts. Please check credentials.\`);
    }
    
    // If authentication is already in progress, wait for it
    if (authenticationInProgress && authenticationPromise) {
      console.log('‚è≥ Authentication already in progress, waiting...');
      try {
        await authenticationPromise;
        return;
      } catch (error) {
        console.log('‚ö†Ô∏è Previous authentication failed, retrying...');
        // Continue with new authentication attempt
      }
    }
    
    // Start new authentication
    authenticationInProgress = true;
    authRetryCount++; // Increment retry count
    console.log(\`üîê Starting Kibana authentication... (attempt \${authRetryCount}/\${MAX_AUTH_RETRIES})\`);
    
    postMessage({
      type: 'AUTHENTICATION_START'
    });

    // Create authentication promise
    authenticationPromise = (async () => {
      const loginResponse = await fetch(origin + '/' + kibanaPath + '/internal/security/login', {
        method: 'POST',
        headers: {
          'accept': '*/*',
          'accept-language': 'en-US,en;q=0.9',
          'cache-control': 'no-cache',
          'content-type': 'application/json',
          'origin': origin,
          'pragma': 'no-cache',
          'priority': 'u=1, i',
          'referer': origin + '/digit-ui/employee/dss/dashboard/provincial-health-dashboard-llin?province=Cabo%20Delgado%20Bloco1&projectTypeId=dbd45c31-de9e-4e62-a9b6-abb818928fd1',
          'sec-fetch-dest': 'empty',
          'sec-fetch-mode': 'cors',
          'sec-fetch-site': 'same-origin',
          'x-elastic-internal-origin': 'Kibana',
          'kbn-xsrf': 'true',
          'x-kbn-context': '{"type":"application","name":"security_login","url":"/' + kibanaPath + '/login"}'
        },
        credentials: 'include',
        body: JSON.stringify({
          "providerType": username,
          "providerName": password,
          "currentURL": origin + "/" + kibanaPath + "/login"
        })
      });

      if (!loginResponse.ok) {
        throw new Error('Kibana authentication failed: ' + loginResponse.statusText);
      }
      
      return loginResponse;
    })();

    // Wait for authentication to complete
    await authenticationPromise;
    
    // Mark as authenticated and set session expiry
    isAuthenticated = true;
    authSessionExpiry = Date.now() + AUTH_SESSION_TIMEOUT;
    lastAuthConfig = \`\${origin}|\${kibanaPath}|\${username}|\${password}\`;
    authRetryCount = 0; // Reset retry count on successful authentication
    
    console.log('‚úÖ Kibana authentication successful');
    postMessage({
      type: 'AUTHENTICATION_SUCCESS'
    });
    
  } catch (error) {
    // Reset authentication state on failure
    isAuthenticated = false;
    authSessionExpiry = null;
    lastAuthConfig = null;
    
    console.error('‚ùå Kibana authentication failed:', error);
    postMessage({
      type: 'AUTHENTICATION_ERROR',
      error: error.message
    });
    throw error;
  } finally {
    // Reset authentication progress state
    authenticationInProgress = false;
    authenticationPromise = null;
  }
}

// Main fetch function
async function fetchElasticsearchData(config) {
  const {
    // Required parameters
    indexName,
    query,
    sourceFields,
    
    // Optional parameters with defaults
    maxRecordLimit = 100000,
    maxBatchSize = 10000,
    parallelBatches = 4,
    
    // Connection parameters
    kibanaPath = 'kibana',
    origin = self.location.origin,
    authKey,
    
    // Authentication parameters
    username,
    password,
    requiresAuth = true,
    
    // Request tracking
    requestId = Date.now().toString()
  } = config;

  try {
    // Set current request ID and reset cancelled flag
    currentRequestId = requestId;
    isCancelled = false;
    activeRequests.set(requestId, true);
    
    console.log(\`üöÄ Starting Elasticsearch fetch with config:\`, {
      indexName,
      maxRecordLimit,
      maxBatchSize,
      parallelBatches,
      requestId
    });

    // Check if request was cancelled before starting
    if (isCancelled) {
      postMessage({
        type: 'FETCH_CANCELLED',
        payload: { requestId }
      });
      return;
    }

    postMessage({
      type: 'FETCH_START',
      payload: { requestId }
    });

    // Step 1: Authenticate with Kibana if required
    if (requiresAuth && username && password) {
      console.log('üîê Step 1: Authenticating with Kibana...');
      
      try {
        await authenticateKibana({
          origin,
          kibanaPath,
          username,
          password,
          requestId
        });
        
        // Wait a moment after authentication
        await new Promise(resolve => setTimeout(resolve, 1000));
        
        // Check if cancelled after authentication
        if (isCancelled) {
          postMessage({
            type: 'FETCH_CANCELLED',
            payload: { requestId }
          });
          return;
        }
        
      } catch (error) {
        postMessage({
          type: 'AUTHENTICATION_REQUIRED',
          payload: { requestId, error: error.message }
        });
        return;
      }
    }

    // Step 2: Get total count using _count API
    console.log(\`üìä Step 2: Getting total count for query...\`);
    
    const countQuery = { query };
    
    // Construct authKey if not provided
    let finalAuthKey = authKey || '';
    if (!finalAuthKey && username && password) {
      
      finalAuthKey = \`Basic \${BasicAuth}\`;
      console.log('üîë Constructed Basic auth key from credentials', finalAuthKey,username,password);
    }
    
    const countHeaders = {
      'Content-Type': 'application/json',
      'kbn-xsrf': 'true'
    };
    
    // Only add Authorization header if we have an auth key
    if (finalAuthKey) {
      countHeaders.Authorization = finalAuthKey;
    }
    
    const countResponse = await fetch(
      \`\${origin}/\${kibanaPath}/api/console/proxy?path=%2F\${indexName}%2F_count&method=POST\`,
      {
        method: 'POST',
        headers: countHeaders,
        credentials: 'include',
        body: JSON.stringify(countQuery)
      }
    );

    if (countResponse.status === 401 || countResponse.status === 403) {
      // Reset authentication state
      isAuthenticated = false;
      authSessionExpiry = null;
      lastAuthConfig = null;
      
      console.error('‚ùå Authentication failed for count API');
      postMessage({
        type: 'AUTHENTICATION_REQUIRED',
        payload: { 
          requestId, 
          error: 'Authentication failed. Please check your credentials and try again.' 
        }
      });
      return;
    }
    
    const countData = await countResponse.json();
    const totalAvailable = countData?.count || 0;
    
    console.log(\`üìä Total records available: \${totalAvailable.toLocaleString()}\`);

    // Step 3: Determine effective fetch limit
    const effectiveLimit = Math.min(maxRecordLimit, totalAvailable);
    console.log(\`üìä Will fetch: \${effectiveLimit.toLocaleString()} records (limit: \${maxRecordLimit.toLocaleString()})\`);

    // Step 4: Check if we need to use Scroll API for large datasets
    const MAX_WINDOW_SIZE = 10000; // Elasticsearch's default max_result_window
    // Use Scroll API only if:
    // 1. We want to fetch more than 10k records AND
    // 2. The total available data is more than 10k (otherwise regular search will work)
    const needsScrollAPI = effectiveLimit > MAX_WINDOW_SIZE && totalAvailable > MAX_WINDOW_SIZE;
    
    console.log(\`üîç Scroll API Decision: effectiveLimit=\${effectiveLimit}, totalAvailable=\${totalAvailable}, needsScrollAPI=\${needsScrollAPI}\`);
    
    if (needsScrollAPI) {
      console.log(\`üîÑ Using Scroll API for large dataset (\${effectiveLimit} > \${MAX_WINDOW_SIZE})\`);
      return await fetchDataUsingScrollAPI({
        indexName,
        query,
        sourceFields,
        effectiveLimit,
        maxBatchSize,
        requestId,
        kibanaPath,
        origin,
        finalAuthKey: finalAuthKey || authKey,
        username,
        password,
        parallelBatches
      });
    }

    // Step 5: Calculate batching strategy for regular API
    const optimalBatchSize = Math.min(maxBatchSize, Math.max(1000, Math.ceil(effectiveLimit / 10)));
    const totalBatches = Math.ceil(effectiveLimit / optimalBatchSize);
    
    console.log(\`üì¶ Batching strategy: \${totalBatches} batches of \${optimalBatchSize} records each\`);
    console.log(\`üîÑ Will process \${parallelBatches} batches in parallel\`);

    // Check if cancelled before processing
    if (isCancelled) {
      postMessage({
        type: 'FETCH_CANCELLED',
        payload: { requestId }
      });
      return;
    }

    // Step 5: Process batches in parallel chunks
    const allHits = [];
    let processedBatches = 0;

    for (let chunkStart = 0; chunkStart < totalBatches; chunkStart += parallelBatches) {
      // Check if cancelled before each chunk
      if (isCancelled || !activeRequests.has(requestId)) {
        postMessage({
          type: 'FETCH_CANCELLED',
          payload: { requestId }
        });
        return;
      }

      const chunkEnd = Math.min(chunkStart + parallelBatches, totalBatches);
      console.log(\`üì¶ Processing batches \${chunkStart + 1} to \${chunkEnd} (of \${totalBatches} total)\`);

      // Create batch promises for this chunk
      const batchPromises = [];
      
      for (let batchIndex = chunkStart; batchIndex < chunkEnd; batchIndex++) {
        const offset = batchIndex * optimalBatchSize;
        const size = Math.min(optimalBatchSize, effectiveLimit - offset);
        
        if (size <= 0) break;
        
        console.log(\`üî¢ Batch \${batchIndex + 1}: offset=\${offset}, size=\${size}\`);
        
        const searchQuery = {
          _source: sourceFields,
          query: query,
          from: offset,
          size: size
        };
        
        const batchPromise = fetchSingleBatch(
          indexName,
          searchQuery,
          batchIndex,
          kibanaPath,
          origin,
          finalAuthKey || authKey,
          username,
          password
        );
        
        batchPromises.push(batchPromise);
      }

      // Execute this chunk of batches in parallel with retry logic
      console.log(\`‚è≥ Executing \${batchPromises.length} batches in parallel...\`);
      const batchResults = await Promise.all(batchPromises);

      // Process results and identify failed batches for retry
      let hasAuthError = false;
      const failedBatches = [];
      
      for (const result of batchResults) {
        if (result.error) {
          console.log(\`‚ùå Batch \${result.batchIndex + 1} failed: \${result.error}\`);
          if (result.error === 'AUTHENTICATION_REQUIRED') {
            hasAuthError = true;
            break; // Stop processing if authentication is required
          }
          // Mark batch for retry if it's not an auth error
          failedBatches.push(result.batchIndex);
        } else {
          console.log(\`‚úÖ Batch \${result.batchIndex + 1} succeeded: \${result.hits.length} records\`);
          allHits.push(...result.hits);
          processedBatches++;
        }
      }

      // Retry failed batches (up to 2 retries per batch)
      if (!hasAuthError && failedBatches.length > 0) {
        console.log(\`üîÑ Retrying \${failedBatches.length} failed batches...\`);
        
        for (const failedBatchIndex of failedBatches) {
          let retryCount = 0;
          const maxRetries = 2;
          let retrySuccess = false;
          
          while (retryCount < maxRetries && !retrySuccess && !isCancelled) {
            retryCount++;
            console.log(\`üîÑ Retry \${retryCount}/\${maxRetries} for batch \${failedBatchIndex + 1}\`);
            
            // Wait a bit before retry
            await new Promise(resolve => setTimeout(resolve, 1000 * retryCount));
            
            const offset = failedBatchIndex * optimalBatchSize;
            const size = Math.min(optimalBatchSize, effectiveLimit - offset);
            
            const retrySearchQuery = {
              _source: sourceFields,
              query: query,
              from: offset,
              size: size
            };
            
            try {
              const retryResult = await fetchSingleBatch(
                indexName,
                retrySearchQuery,
                failedBatchIndex,
                kibanaPath,
                origin,
                finalAuthKey || authKey,
                username,
                password
              );
              
              if (retryResult.error) {
                console.log(\`‚ùå Retry \${retryCount} failed for batch \${failedBatchIndex + 1}: \${retryResult.error}\`);
              } else {
                console.log(\`‚úÖ Retry \${retryCount} succeeded for batch \${failedBatchIndex + 1}: \${retryResult.hits.length} records\`);
                allHits.push(...retryResult.hits);
                processedBatches++;
                retrySuccess = true;
              }
            } catch (error) {
              console.log(\`‚ùå Retry \${retryCount} failed for batch \${failedBatchIndex + 1}: \${error.message}\`);
            }
          }
          
          if (!retrySuccess) {
            console.error(\`üíÄ Batch \${failedBatchIndex + 1} failed permanently after \${maxRetries} retries\`);
          }
        }
      }
      
      // If authentication error occurred, stop and report the error
      if (hasAuthError) {
        console.error('‚ùå Authentication failed during batch processing');
        
        // Reset authentication state
        isAuthenticated = false;
        authSessionExpiry = null;
        lastAuthConfig = null;
        
        postMessage({
          type: 'AUTHENTICATION_REQUIRED',
          payload: { 
            requestId, 
            error: 'Authentication expired during batch processing. Please retry the operation.',
            partialResults: allHits.length > 0 ? allHits : null,
            recordsReceived: allHits.length
          }
        });
        return;
      }

      // Send progress update
      const progress = (processedBatches / totalBatches) * 100;
      postMessage({
        type: 'FETCH_PROGRESS',
        payload: {
          batchesCompleted: processedBatches,
          totalBatches: totalBatches,
          recordsReceived: allHits.length,
          progress: progress,
          requestId: requestId
        }
      });

      console.log(\`üìà Progress: \${processedBatches}/\${totalBatches} batches completed, \${allHits.length} total records\`);

      // Small delay between chunks to prevent overwhelming the server
      if (chunkEnd < totalBatches) {
        await new Promise(resolve => setTimeout(resolve, 100));
      }
    }

    // Final check before sending success
    if (isCancelled) {
      postMessage({
        type: 'FETCH_CANCELLED',
        payload: { requestId }
      });
      return;
    }

    // Step 6: Send final results with detailed summary
    const fetchSummary = {
      recordsFetched: allHits.length,
      totalAvailable: totalAvailable,
      expectedBatches: totalBatches,
      processedBatches: processedBatches,
      completionRate: ((allHits.length / totalAvailable) * 100).toFixed(1) + '%',
      avgRecordsPerBatch: processedBatches > 0 ? Math.round(allHits.length / processedBatches) : 0
    };
    
    console.log(\`‚úÖ Fetch completed:\`, fetchSummary);
    
    if (allHits.length < totalAvailable) {
      console.warn(\`‚ö†Ô∏è Incomplete fetch: Expected \${totalAvailable}, got \${allHits.length} (\${fetchSummary.completionRate})\`);
    }
    
    postMessage({
      type: 'FETCH_SUCCESS',
      payload: {
        hits: allHits,
        totalRecords: allHits.length,
        totalAvailable: totalAvailable,
        batchesProcessed: processedBatches,
        fetchSummary: fetchSummary,
        config: {
          indexName,
          maxRecordLimit,
          maxBatchSize,
          parallelBatches,
          effectiveLimit,
          optimalBatchSize,
          totalBatches
        },
        requestId: requestId
      }
    });

  } catch (error) {
    // Don't send error if request was cancelled
    if (!isCancelled) {
      console.error(\`‚ùå Fetch failed:\`, error);
      postMessage({
        type: 'FETCH_ERROR',
        error: error.message,
        stack: error.stack,
        payload: { requestId: requestId }
      });
    }
  } finally {
    // Clean up request tracking
    if (requestId) {
      activeRequests.delete(requestId);
    }
  }
}

// Fetch a single batch
async function fetchSingleBatch(indexName, searchQuery, batchIndex, kibanaPath, origin, authKey, username, password) {
  try {
    // Construct authKey if not provided
    let finalAuthKey = authKey || '';
    if (!finalAuthKey && username && password) {
      finalAuthKey = \`Basic \${BasicAuth}\`;
    }
    
    const searchHeaders = {
      'Content-Type': 'application/json',
      'kbn-xsrf': 'true'
    };
    
    // Only add Authorization header if we have an auth key
    if (finalAuthKey) {
      searchHeaders.Authorization = finalAuthKey;
    }
    
    const response = await fetch(
      \`\${origin}/\${kibanaPath}/api/console/proxy?path=%2F\${indexName}%2F_search&method=POST\`,
      {
        method: 'POST',
        headers: searchHeaders,
        credentials: 'include',
        body: JSON.stringify(searchQuery)
      }
    );

    if (response.status === 401 || response.status === 403) {
      // Reset authentication state to force re-authentication on next attempt
      isAuthenticated = false;
      authSessionExpiry = null;
      lastAuthConfig = null;
      throw new Error('AUTHENTICATION_REQUIRED');
    }

    const data = await response.json();
    
    console.log(\`üîç Batch \${batchIndex + 1} response:\`, {
      status: response.status,
      hasData: !!data,
      hasHits: !!(data && data.hits),
      hasHitsArray: !!(data && data.hits && data.hits.hits),
      hitsLength: data?.hits?.hits?.length || 0,
      totalValue: data?.hits?.total?.value || data?.hits?.total || 0,
      searchQuery: searchQuery
    });
    
    if (data && data.hits && data.hits.hits) {
      const result = {
        batchIndex,
        hits: data.hits.hits,
        total: data.hits.total?.value || data.hits.total || data.hits.hits.length
      };
      console.log(\`‚úÖ Batch \${batchIndex + 1} parsed successfully: \${result.hits.length} records\`);
      return result;
    }
    
    console.warn(\`‚ö†Ô∏è Batch \${batchIndex + 1} returned no valid data:\`, data);
    return {
      batchIndex,
      hits: [],
      total: 0
    };
    
  } catch (error) {
    console.error(\`‚ùå Batch \${batchIndex + 1} failed with error:\`, {
      message: error.message,
      status: error.status,
      stack: error.stack,
      searchQuery: searchQuery
    });
    
    return {
      batchIndex,
      hits: [],
      total: 0,
      error: error.message
    };
  }
}

// Scroll API implementation for large datasets with parallel processing
async function fetchDataUsingScrollAPI({
  indexName,
  query,
  sourceFields,
  effectiveLimit,
  maxBatchSize,
  requestId,
  kibanaPath,
  origin,
  finalAuthKey,
  username,
  password,
  parallelBatches = 1
}) {
  console.log(\`üîÑ Starting Scroll API fetch for \${effectiveLimit} records with \${parallelBatches} parallel contexts\`);
  
  const allHits = [];
  const scrollTimeout = '5m'; // Keep scroll context alive for 5 minutes
  const scrollSize = Math.min(maxBatchSize, 5000); // Scroll batch size per context
  
  // Implement parallel scroll processing if parallelBatches > 1
  if (parallelBatches > 1) {
    return await fetchDataUsingParallelScrollAPI({
      indexName,
      query,
      sourceFields,
      effectiveLimit,
      scrollSize,
      scrollTimeout,
      parallelBatches,
      requestId,
      kibanaPath,
      origin,
      finalAuthKey,
      username,
      password
    });
  }
  
  // Single scroll context implementation
  let scrollId = null;
  let fetchedCount = 0;
  let scrollBatch = 0;
  
  try {
    // Step 1: Initial scroll search
    const initialQuery = {
      _source: sourceFields,
      query: query,
      size: scrollSize
    };
    
    console.log(\`üìú Initiating scroll search with batch size: \${scrollSize}\`);
    console.log(\`üîê Scroll API auth: finalAuthKey=\${finalAuthKey ? finalAuthKey.substring(0, 20) + '...' : 'null'}, username=\${username || 'null'}\`);
    
    const headers = {
      'Content-Type': 'application/json',
      'kbn-xsrf': 'true'
    };
    
    // Add authentication headers (same logic as fetchSingleBatch)
    if (finalAuthKey) {
      // finalAuthKey could be "Basic xxx" or just the API key
      if (finalAuthKey.startsWith('Basic ') || finalAuthKey.startsWith('ApiKey ')) {
        headers['Authorization'] = finalAuthKey;
      } else {
        headers['Authorization'] = \`ApiKey \${finalAuthKey}\`;
      }
    } else if (username && password) {
      headers['Authorization'] = \`Basic \${btoa(\`\${username}:\${password}\`)}\`;
    }
    
    const initialResponse = await fetch(
      \`\${origin}/\${kibanaPath}/api/console/proxy?path=\${encodeURIComponent(\`/\${indexName}/_search?scroll=\${scrollTimeout}\`)}&method=POST\`,
      {
        method: 'POST',
        headers: headers,
        credentials: 'include',
        body: JSON.stringify(initialQuery)
      }
    );
    
    if (initialResponse.status === 401 || initialResponse.status === 403) {
      throw new Error('AUTHENTICATION_REQUIRED');
    }
    
    const initialData = await initialResponse.json();
    
    if (!initialData || !initialData.hits || !initialData.hits.hits) {
      throw new Error('Invalid initial scroll response');
    }
    
    scrollId = initialData._scroll_id;
    const firstBatch = initialData.hits.hits;
    allHits.push(...firstBatch);
    fetchedCount += firstBatch.length;
    scrollBatch++;
    
    console.log(\`üìú Initial scroll batch \${scrollBatch}: \${firstBatch.length} records (total: \${fetchedCount})\`);
    
    // Send progress update
    postMessage({
      type: 'FETCH_PROGRESS',
      payload: {
        batchesCompleted: scrollBatch,
        totalBatches: Math.ceil(effectiveLimit / scrollSize),
        recordsProcessed: fetchedCount,
        totalRecords: effectiveLimit,
        progress: (fetchedCount / effectiveLimit) * 100,
        requestId: requestId
      }
    });
    
    // Step 2: Continue scrolling until we have all data or reach limit
    while (scrollId && fetchedCount < effectiveLimit && !isCancelled) {
      const scrollQuery = {
        scroll: scrollTimeout,
        scroll_id: scrollId
      };
      
      console.log(\`üìú Fetching scroll batch \${scrollBatch + 1}...\`);
      
      const scrollResponse = await fetch(
        \`\${origin}/\${kibanaPath}/api/console/proxy?path=\${encodeURIComponent('/_search/scroll')}&method=POST\`,
        {
          method: 'POST',
          headers: headers,
          credentials: 'include',
          body: JSON.stringify(scrollQuery)
        }
      );
      
      if (scrollResponse.status === 401 || scrollResponse.status === 403) {
        throw new Error('AUTHENTICATION_REQUIRED');
      }
      
      const scrollData = await scrollResponse.json();
      
      if (!scrollData || !scrollData.hits || !scrollData.hits.hits) {
        console.log(\`üìú No more data in scroll batch \${scrollBatch + 1}\`);
        break;
      }
      
      const batchHits = scrollData.hits.hits;
      
      if (batchHits.length === 0) {
        console.log(\`üìú Empty scroll batch \${scrollBatch + 1}, ending scroll\`);
        break;
      }
      
      // Limit the number of records we add to not exceed effectiveLimit
      const remainingLimit = effectiveLimit - fetchedCount;
      const hitsToAdd = batchHits.slice(0, remainingLimit);
      
      allHits.push(...hitsToAdd);
      fetchedCount += hitsToAdd.length;
      scrollBatch++;
      scrollId = scrollData._scroll_id;
      
      console.log(\`üìú Scroll batch \${scrollBatch}: \${hitsToAdd.length} records (total: \${fetchedCount})\`);
      
      // Send progress update
      postMessage({
        type: 'FETCH_PROGRESS',
        payload: {
          batchesCompleted: scrollBatch,
          totalBatches: Math.ceil(effectiveLimit / scrollSize),
          recordsProcessed: fetchedCount,
          totalRecords: effectiveLimit,
          progress: (fetchedCount / effectiveLimit) * 100,
          requestId: requestId
        }
      });
      
      // Small delay to prevent overwhelming the server
      await new Promise(resolve => setTimeout(resolve, 100));
    }
    
    // Step 3: Clear scroll context
    if (scrollId) {
      try {
        console.log(\`üìú Clearing scroll context: \${scrollId}\`);
        await fetch(
          \`\${origin}/\${kibanaPath}/api/console/proxy?path=\${encodeURIComponent('/_search/scroll')}&method=DELETE\`,
          {
            method: 'DELETE',
            headers: headers,
            credentials: 'include',
            body: JSON.stringify({ scroll_id: scrollId })
          }
        );
      } catch (clearError) {
        console.warn(\`‚ö†Ô∏è Failed to clear scroll context: \${clearError.message}\`);
      }
    }
    
    // Step 4: Send final results
    const fetchSummary = {
      recordsFetched: allHits.length,
      totalAvailable: effectiveLimit,
      expectedBatches: Math.ceil(effectiveLimit / scrollSize),
      processedBatches: scrollBatch,
      completionRate: ((allHits.length / effectiveLimit) * 100).toFixed(1) + '%',
      avgRecordsPerBatch: scrollBatch > 0 ? Math.round(allHits.length / scrollBatch) : 0,
      method: 'Scroll API'
    };
    
    console.log(\`‚úÖ Scroll API fetch completed:\`, fetchSummary);
    
    if (allHits.length < effectiveLimit) {
      console.warn(\`‚ö†Ô∏è Incomplete scroll fetch: Expected \${effectiveLimit}, got \${allHits.length} (\${fetchSummary.completionRate})\`);
    }
    
    postMessage({
      type: 'FETCH_SUCCESS',
      payload: {
        hits: allHits,
        totalRecords: allHits.length,
        totalAvailable: effectiveLimit,
        batchesProcessed: scrollBatch,
        fetchSummary: fetchSummary,
        config: {
          indexName,
          method: 'Scroll API',
          scrollSize,
          effectiveLimit
        },
        requestId: requestId
      }
    });
    
  } catch (error) {
    console.error(\`‚ùå Scroll API fetch failed:\`, error);
    
    // Clear scroll context on error
    if (scrollId) {
      try {
        await fetch(
          \`\${origin}/\${kibanaPath}/api/console/proxy?path=\${encodeURIComponent('/_search/scroll')}&method=DELETE\`,
          {
            method: 'DELETE',
            headers: {
              'Content-Type': 'application/json',
              ...(finalAuthKey ? { 'Authorization': \`ApiKey \${finalAuthKey}\` } : 
                  username && password ? { 'Authorization': \`Basic \${btoa(\`\${username}:\${password}\`)}\` } : {})
            },
            credentials: 'include',
            body: JSON.stringify({ scroll_id: scrollId })
          }
        );
      } catch (clearError) {
        console.warn(\`‚ö†Ô∏è Failed to clear scroll context on error: \${clearError.message}\`);
      }
    }
    
    if (error.message === 'AUTHENTICATION_REQUIRED') {
      // Reset authentication state
      isAuthenticated = false;
      authSessionExpiry = null;
      lastAuthConfig = null;
      
      postMessage({
        type: 'AUTHENTICATION_REQUIRED',
        payload: { 
          requestId, 
          error: 'Authentication expired during scroll fetch. Please retry the operation.',
          partialResults: allHits.length > 0 ? allHits : null,
          recordsReceived: allHits.length
        }
      });
    } else {
      postMessage({
        type: 'FETCH_ERROR',
        payload: {
          error: error.message,
          details: error.stack,
          requestId: requestId,
          partialResults: allHits.length > 0 ? allHits : null,
          recordsReceived: allHits.length
        }
      });
    }
  }
}

// Parallel Scroll API implementation for large datasets
async function fetchDataUsingParallelScrollAPI({
  indexName,
  query,
  sourceFields,
  effectiveLimit,
  scrollSize,
  scrollTimeout,
  parallelBatches,
  requestId,
  kibanaPath,
  origin,
  finalAuthKey,
  username,
  password
}) {
  console.log(\`üîÑ Starting Parallel Scroll API with \${parallelBatches} contexts for \${effectiveLimit} records\`);
  
  const allHits = [];
  const scrollContexts = [];
  const recordsPerContext = Math.ceil(effectiveLimit / parallelBatches);
  
  try {
    // Phase 1: Initialize multiple scroll contexts
    console.log(\`üìú Phase 1: Initializing \${parallelBatches} scroll contexts\`);
    
    const headers = {
      'Content-Type': 'application/json',
      'kbn-xsrf': 'true'
    };
    
    // Add authentication headers
    if (finalAuthKey) {
      if (finalAuthKey.startsWith('Basic ') || finalAuthKey.startsWith('ApiKey ')) {
        headers['Authorization'] = finalAuthKey;
      } else {
        headers['Authorization'] = \`ApiKey \${finalAuthKey}\`;
      }
    } else if (username && password) {
      headers['Authorization'] = \`Basic \${btoa(\`\${username}:\${password}\`)}\`;
    }
    
    // Create initialization promises for all contexts
    const initPromises = Array.from({ length: parallelBatches }, async (_, contextIndex) => {
      const initialQuery = {
        _source: sourceFields,
        query: query,
        size: scrollSize
      };
      
      console.log(\`üìú Initializing scroll context \${contextIndex + 1}/\${parallelBatches}\`);
      
      const response = await fetch(
        \`\${origin}/\${kibanaPath}/api/console/proxy?path=\${encodeURIComponent(\`/\${indexName}/_search?scroll=\${scrollTimeout}\`)}&method=POST\`,
        {
          method: 'POST',
          headers: headers,
          credentials: 'include',
          body: JSON.stringify(initialQuery)
        }
      );
      
      if (response.status === 401 || response.status === 403) {
        throw new Error('AUTHENTICATION_REQUIRED');
      }
      
      const data = await response.json();
      
      if (!data || !data.hits || !data.hits.hits) {
        throw new Error(\`Invalid scroll response for context \${contextIndex + 1}\`);
      }
      
      return {
        contextIndex,
        scrollId: data._scroll_id,
        hits: data.hits.hits,
        totalInThisContext: data.hits.total?.value || data.hits.total || 0,
        finished: data.hits.hits.length === 0
      };
    });
    
    // Wait for all contexts to initialize
    const initialResults = await Promise.all(initPromises);
    
    // Process initial results
    for (const result of initialResults) {
      if (result.hits.length > 0) {
        allHits.push(...result.hits);
        scrollContexts.push(result);
        console.log(\`üìú Context \${result.contextIndex + 1}: initialized with \${result.hits.length} records\`);
      } else {
        console.log(\`üìú Context \${result.contextIndex + 1}: no initial data, marking as finished\`);
      }
    }
    
    // Phase 2: Continue scrolling all active contexts in parallel
    console.log(\`üìú Phase 2: Parallel scrolling \${scrollContexts.length} active contexts\`);
    
    let totalBatches = 0;
    const maxBatchesPerContext = Math.ceil(recordsPerContext / scrollSize);
    
    while (scrollContexts.length > 0 && allHits.length < effectiveLimit && !isCancelled) {
      // Create scroll promises for all active contexts
      const scrollPromises = scrollContexts.map(async (context) => {
        if (context.finished) return null;
        
        const scrollQuery = {
          scroll: scrollTimeout,
          scroll_id: context.scrollId
        };
        
        try {
          const response = await fetch(
            \`\${origin}/\${kibanaPath}/api/console/proxy?path=\${encodeURIComponent('/_search/scroll')}&method=POST\`,
            {
              method: 'POST',
              headers: headers,
              credentials: 'include',
              body: JSON.stringify(scrollQuery)
            }
          );
          
          if (response.status === 401 || response.status === 403) {
            throw new Error('AUTHENTICATION_REQUIRED');
          }
          
          const data = await response.json();
          
          if (!data || !data.hits || !data.hits.hits || data.hits.hits.length === 0) {
            return {
              contextIndex: context.contextIndex,
              finished: true,
              hits: [],
              scrollId: context.scrollId
            };
          }
          
          return {
            contextIndex: context.contextIndex,
            finished: false,
            hits: data.hits.hits,
            scrollId: data._scroll_id
          };
          
        } catch (error) {
          console.error(\`‚ùå Context \${context.contextIndex + 1} scroll error:\`, error);
          return {
            contextIndex: context.contextIndex,
            finished: true,
            hits: [],
            scrollId: context.scrollId,
            error: error.message
          };
        }
      });
      
      // Execute all scroll requests in parallel
      const scrollResults = await Promise.all(scrollPromises);
      
      // Process results and update contexts
      let activeContextCount = 0;
      let batchHitsCount = 0;
      
      for (let i = scrollContexts.length - 1; i >= 0; i--) {
        const result = scrollResults[i];
        
        if (!result) continue;
        
        if (result.error) {
          console.error(\`‚ùå Context \${result.contextIndex + 1} failed: \${result.error}\`);
          // Clear this context's scroll
          try {
            await fetch(
              \`\${origin}/\${kibanaPath}/api/console/proxy?path=\${encodeURIComponent('/_search/scroll')}&method=DELETE\`,
              {
                method: 'DELETE',
                headers: headers,
                credentials: 'include',
                body: JSON.stringify({ scroll_id: result.scrollId })
              }
            );
          } catch (clearError) {
            console.warn(\`‚ö†Ô∏è Failed to clear failed context \${result.contextIndex + 1}: \${clearError.message}\`);
          }
          scrollContexts.splice(i, 1);
          continue;
        }
        
        if (result.finished) {
          console.log(\`üìú Context \${result.contextIndex + 1}: finished scrolling\`);
          // Clear this context's scroll
          try {
            await fetch(
              \`\${origin}/\${kibanaPath}/api/console/proxy?path=\${encodeURIComponent('/_search/scroll')}&method=DELETE\`,
              {
                method: 'DELETE',
                headers: headers,
                credentials: 'include',
                body: JSON.stringify({ scroll_id: result.scrollId })
              }
            );
          } catch (clearError) {
            console.warn(\`‚ö†Ô∏è Failed to clear finished context \${result.contextIndex + 1}: \${clearError.message}\`);
          }
          scrollContexts.splice(i, 1);
        } else {
          // Update context with new scroll ID and add hits
          scrollContexts[i].scrollId = result.scrollId;
          
          // Limit hits to not exceed effectiveLimit
          const remainingLimit = effectiveLimit - allHits.length;
          const hitsToAdd = result.hits.slice(0, remainingLimit);
          
          if (hitsToAdd.length > 0) {
            allHits.push(...hitsToAdd);
            batchHitsCount += hitsToAdd.length;
            console.log(\`üìú Context \${result.contextIndex + 1}: +\${hitsToAdd.length} records (total: \${allHits.length})\`);
          }
          
          activeContextCount++;
        }
      }
      
      totalBatches++;
      
      // Send progress update
      const progress = Math.min((allHits.length / effectiveLimit) * 100, 100);
      postMessage({
        type: 'FETCH_PROGRESS',
        payload: {
          batchesCompleted: totalBatches,
          totalBatches: maxBatchesPerContext * parallelBatches,
          recordsProcessed: allHits.length,
          totalRecords: effectiveLimit,
          progress: progress,
          activeContexts: activeContextCount,
          requestId: requestId
        }
      });
      
      console.log(\`üìä Parallel batch \${totalBatches}: +\${batchHitsCount} records, \${activeContextCount} active contexts, \${allHits.length}/\${effectiveLimit} total\`);
      
      // Small delay between batches to prevent overwhelming the server
      if (activeContextCount > 0) {
        await new Promise(resolve => setTimeout(resolve, 50));
      }
    }
    
    // Phase 3: Clean up any remaining scroll contexts
    if (scrollContexts.length > 0) {
      console.log(\`üìú Phase 3: Cleaning up \${scrollContexts.length} remaining scroll contexts\`);
      
      const cleanupPromises = scrollContexts.map(async (context) => {
        try {
          await fetch(
            \`\${origin}/\${kibanaPath}/api/console/proxy?path=\${encodeURIComponent('/_search/scroll')}&method=DELETE\`,
            {
              method: 'DELETE',
              headers: headers,
              credentials: 'include',
              body: JSON.stringify({ scroll_id: context.scrollId })
            }
          );
        } catch (error) {
          console.warn(\`‚ö†Ô∏è Failed to clear context \${context.contextIndex + 1}: \${error.message}\`);
        }
      });
      
      await Promise.all(cleanupPromises);
    }
    
    // Phase 4: Send final results
    const fetchSummary = {
      recordsFetched: allHits.length,
      totalAvailable: effectiveLimit,
      expectedBatches: maxBatchesPerContext * parallelBatches,
      processedBatches: totalBatches,
      completionRate: ((allHits.length / effectiveLimit) * 100).toFixed(1) + '%',
      avgRecordsPerBatch: totalBatches > 0 ? Math.round(allHits.length / totalBatches) : 0,
      method: \`Parallel Scroll API (\${parallelBatches} contexts)\`,
      parallelContexts: parallelBatches
    };
    
    console.log(\`‚úÖ Parallel Scroll API completed:\`, fetchSummary);
    
    if (allHits.length < effectiveLimit) {
      console.warn(\`‚ö†Ô∏è Incomplete parallel scroll fetch: Expected \${effectiveLimit}, got \${allHits.length} (\${fetchSummary.completionRate})\`);
    }
    
    postMessage({
      type: 'FETCH_SUCCESS',
      payload: {
        hits: allHits,
        totalRecords: allHits.length,
        totalAvailable: effectiveLimit,
        batchesProcessed: totalBatches,
        fetchSummary: fetchSummary,
        config: {
          indexName,
          method: \`Parallel Scroll API (\${parallelBatches} contexts)\`,
          scrollSize,
          effectiveLimit,
          parallelBatches
        },
        requestId: requestId
      }
    });
    
  } catch (error) {
    console.error(\`‚ùå Parallel Scroll API failed:\`, error);
    
    // Clean up all scroll contexts on error
    if (scrollContexts.length > 0) {
      const cleanupPromises = scrollContexts.map(async (context) => {
        try {
          await fetch(
            \`\${origin}/\${kibanaPath}/api/console/proxy?path=\${encodeURIComponent('/_search/scroll')}&method=DELETE\`,
            {
              method: 'DELETE',
              headers: {
                'Content-Type': 'application/json',
                'kbn-xsrf': 'true',
                ...(finalAuthKey ? { 'Authorization': finalAuthKey.startsWith('Basic ') || finalAuthKey.startsWith('ApiKey ') ? finalAuthKey : \`ApiKey \${finalAuthKey}\` } : 
                    username && password ? { 'Authorization': \`Basic \${btoa(\`\${username}:\${password}\`)}\` } : {})
              },
              credentials: 'include',
              body: JSON.stringify({ scroll_id: context.scrollId })
            }
          );
        } catch (clearError) {
          console.warn(\`‚ö†Ô∏è Failed to clear context \${context.contextIndex + 1} on error: \${clearError.message}\`);
        }
      });
      
      await Promise.all(cleanupPromises);
    }
    
    if (error.message === 'AUTHENTICATION_REQUIRED') {
      // Reset authentication state
      isAuthenticated = false;
      authSessionExpiry = null;
      lastAuthConfig = null;
      
      postMessage({
        type: 'AUTHENTICATION_REQUIRED',
        payload: { 
          requestId, 
          error: 'Authentication expired during parallel scroll fetch. Please retry the operation.',
          partialResults: allHits.length > 0 ? allHits : null,
          recordsReceived: allHits.length
        }
      });
    } else {
      postMessage({
        type: 'FETCH_ERROR',
        payload: {
          error: error.message,
          details: error.stack,
          requestId: requestId,
          partialResults: allHits.length > 0 ? allHits : null,
          recordsReceived: allHits.length
        }
      });
    }
  }
}

// Handle worker errors
self.onerror = function(error) {
  postMessage({
    type: 'WORKER_ERROR',
    error: error.message,
    filename: error.filename,
    lineno: error.lineno
  });
};`;
